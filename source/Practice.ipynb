{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from pandas.io.parsers import read_csv\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:72: UserWarning: h5py is running against HDF5 1.10.2 when it was built against 1.10.3, this may cause problems\n",
      "  '{0}.{1}.{2}'.format(*version.hdf5_built_version_tuple)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Convolution2D, MaxPooling2D, Flatten, Dropout\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import model_from_json\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "FTRAIN = '../all/training.csv'\n",
    "FTEST = '../all/test.csv'\n",
    "\n",
    "SPECIALIST_SETTINGS = [\n",
    "    dict(\n",
    "        columns=(\n",
    "            'left_eye_center_x', 'left_eye_center_y',\n",
    "            'right_eye_center_x', 'right_eye_center_y',\n",
    "            ),\n",
    "        flip_indices=((0, 2), (1, 3)),\n",
    "        ),\n",
    "\n",
    "    dict(\n",
    "        columns=(\n",
    "            'nose_tip_x', 'nose_tip_y',\n",
    "            ),\n",
    "        flip_indices=(),\n",
    "        ),\n",
    "\n",
    "    dict(\n",
    "        columns=(\n",
    "            'mouth_left_corner_x', 'mouth_left_corner_y',\n",
    "            'mouth_right_corner_x', 'mouth_right_corner_y',\n",
    "            'mouth_center_top_lip_x', 'mouth_center_top_lip_y',\n",
    "            ),\n",
    "        flip_indices=((0, 2), (1, 3)),\n",
    "        ),\n",
    "\n",
    "    dict(\n",
    "        columns=(\n",
    "            'mouth_center_bottom_lip_x',\n",
    "            'mouth_center_bottom_lip_y',\n",
    "            ),\n",
    "        flip_indices=(),\n",
    "        ),\n",
    "\n",
    "    dict(\n",
    "        columns=(\n",
    "            'left_eye_inner_corner_x', 'left_eye_inner_corner_y',\n",
    "            'right_eye_inner_corner_x', 'right_eye_inner_corner_y',\n",
    "            'left_eye_outer_corner_x', 'left_eye_outer_corner_y',\n",
    "            'right_eye_outer_corner_x', 'right_eye_outer_corner_y',\n",
    "            ),\n",
    "        flip_indices=((0, 2), (1, 3), (4, 6), (5, 7)),\n",
    "        ),\n",
    "\n",
    "    dict(\n",
    "        columns=(\n",
    "            'left_eyebrow_inner_end_x', 'left_eyebrow_inner_end_y',\n",
    "            'right_eyebrow_inner_end_x', 'right_eyebrow_inner_end_y',\n",
    "            'left_eyebrow_outer_end_x', 'left_eyebrow_outer_end_y',\n",
    "            'right_eyebrow_outer_end_x', 'right_eyebrow_outer_end_y',\n",
    "            ),\n",
    "        flip_indices=((0, 2), (1, 3), (4, 6), (5, 7)),\n",
    "        ),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(test=False, cols=None):\n",
    "\n",
    "    fname = FTEST if test else FTRAIN\n",
    "    #테스트가 true면 test.csv 파일, false인경우 training.csv파일\n",
    "    df = read_csv(os.path.expanduser(fname))\n",
    "    \"\"\"os.path모듈에서 제공되는 expanduser를 사용하여 절대 경로를 명시하여 줍니다.\n",
    "    >>> expanduser('~\\\\devanix')\n",
    "    'C:\\\\Documents and Settings\\\\Administrator\\\\devanix' \"\"\"\n",
    "\n",
    "    df['Image'] = df['Image'].apply(lambda im: np.fromstring(im, sep=' '))\n",
    "    \"\"\"Image열은 픽셀 값이 공백으로 구분이 되어 있기 때문에 apply 메서드를 이용하여 \n",
    "    열에 대한 배열을 생성을 합니다.\"\"\"\n",
    "    if cols: # 열에 해당하는 값 가져오기\n",
    "        df = df[list(cols) + ['Image']]\n",
    "\n",
    "    print(df.count()) # 각 열의 값 수를 출력\n",
    "    df = df.dropna() # NaN값에 대한 행 삭제\n",
    "\n",
    "    X = np.vstack(df['Image'].values) / 255. \n",
    "    # 2개 이상의 배열을 합치기 위해 vstack 사용.\n",
    "    # 픽셀 값 = 255 \n",
    "    X = X.astype(np.float32)\n",
    "    # float32로 타입 변환.\n",
    "    if not test: # training.csv 파일에 대한 데이터 처리\n",
    "        y = df[df.columns[:-1]].values # 15개 항목에 대한 데이터 값\n",
    "        y = (y - 48) / 48 # 15개 항목에 대한 데이터 값을 -1 ~ 1사이의 값으로 변환\n",
    "        X, y = shuffle(X, y, random_state=42) \n",
    "        #X, y에 대해 42개의 난수를 생성하여 셔플\n",
    "        y = y.astype(np.float32)\n",
    "    else:\n",
    "        y = None\n",
    "\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load2d(test=False, cols=None):\n",
    "    X, y = load(test, cols)\n",
    "    X = X.reshape(-1, 1, 96, 96)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample(x, y, axis):\n",
    "    img = x.reshape(96, 96)\n",
    "    axis.imshow(img, cmap='gray')\n",
    "    axis.scatter(y[0::2]*48+48, y[1::2]*48+48, marker='x', s=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlippedImageDataGenerator(ImageDataGenerator):\n",
    "    flip_indices = [\n",
    "        (0, 2), (1, 3),\n",
    "        (4, 8), (5, 9), (6, 10), (7, 11),\n",
    "        (12, 16), (13, 17), (14, 18), (15, 19),\n",
    "        (22, 24), (23, 25),\n",
    "        ] #반전 된 이미지에서 keypoint의 위치 변경\n",
    "\n",
    "    def next(self):\n",
    "        X_batch, y_batch = super(FlippedImageDataGenerator, self).next()\n",
    "        batch_size = X_batch.shape[0]\n",
    "        indices = np.random.choice(batch_size, batch_size/2, replace=False)\n",
    "        X_batch[indices] = X_batch[indices, :, :, ::-1]\n",
    "\n",
    "        if y_batch is not None: # x좌표 변경\n",
    "            y_batch[indices, ::2] = y_batch[indices, ::2] * -1\n",
    "\n",
    "            for a, b in self.flip_indices: # left_eye_center_x -> right_eye_center_x\n",
    "                y_batch[indices, a], y_batch[indices, b] = (\n",
    "                    y_batch[indices, b], y_batch[indices, a]\n",
    "                )\n",
    "\n",
    "        return X_batch, y_batch\n",
    "    \"\"\" 반전된 이미지를 training 데이터 X에 단순히 추가하는 방식이 아닌 랜덤으로 반전시킴으로서 메모리 소비를\n",
    "    줄 일수 있다. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (2, 2))`\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (2, 2))`\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "model = Sequential() # 객체 생성\n",
    "\n",
    "model.add(Convolution2D(32, (3, 3), input_shape=(1, 96, 96), data_format='channels_first'))\n",
    "# 텐서의 출력 생성\n",
    "# Convolution2D(32, (3, 3) -> 텐서의 출력 개수\n",
    "# input_shape=(1,96,96) -> 96x96 의 그림 1은 보폭\n",
    "# data_format='channels_first' -> 모양 있는 입력\n",
    "model.add(Activation('relu')) #relu - max(0,x) 처럼 음수에 대해서만 0으로 처리하는 함수\n",
    "\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) # 시간 데이터에 대한 최대 출링 연상 최대 풀링 창의 크기 2x2\n",
    "model.add(Dropout(0.1)) # 무작위 항목을 설정 \n",
    "\n",
    "model.add(Convolution2D(64, 2, 2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Convolution2D(128, 2, 2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1000)) # 노드의 개수\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1000))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_specialists(fname_pretrain=None):\n",
    "    specialists = OrderedDict() #순서대로 저장하는 딕셔너리\n",
    "    start = 0.03\n",
    "    stop = 0.001\n",
    "    nb_epoch = 500 # 학습 epoch(학습 시 한 번에 처리할 블록 길이) 횟수\n",
    "\n",
    "    for setting in SPECIALIST_SETTINGS:\n",
    "\n",
    "        cols = setting['columns']\n",
    "        X, y = load2d(cols=cols)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        model_specialist = model_from_json(model.to_json()) # 모델의 JSON 문자열 반환\n",
    "\n",
    "        if fname_pretrain:\n",
    "            model_specialist.load_weights(fname_pretrain) # 생성 된 HDF5 파일에서의 모델 가중치 로드\n",
    "\n",
    "        model_specialist.layers.pop()\n",
    "        model_specialist.outputs = [model_specialist.layers[-1].output] # 출력 텐서 목록\n",
    "        model_specialist.layers[-1].outbound_nodes = [] #레이어의 병합 목록\n",
    "        model_specialist.add(Dense(len(cols)))\n",
    "\n",
    "        # 최적화\n",
    "        sgd = SGD(lr=start, momentum=0.9, nesterov=True) \n",
    "        \"\"\"SGD 운동량, 학습 속도 감소에 대한 지원\n",
    "        lr = 학습속도, momentum = SGD 가속\"\"\"\n",
    "        model_specialist.compile(loss='mean_squared_error', optimizer=sgd)\n",
    "        # SGD 인스턴스화 , 기본 매개변수로 사용.\n",
    "\n",
    "        # flip_indices 튜플 정의\n",
    "        flipgen = FlippedImageDataGenerator()\n",
    "        flipgen.flip_indices = setting['flip_indices']\n",
    "\n",
    "        # 조기 종료\n",
    "        \"\"\"이전 epoch와 비교해서 오차가 증가하면 학습을 중단하는 부분\"\"\"\n",
    "        early_stop = EarlyStopping(patience=100) #patience - 개선이 없는 epoch 100번 지속되면 학습 종료\n",
    "        learning_rates = np.linspace(start, stop, nb_epoch) # 일정 간격마다 숫자를 반환\n",
    "        change_lr = LearningRateScheduler(lambda epoch: float(learning_rates[epoch])) # 시간 반환\n",
    "\n",
    "        print(\"Training model : {} ,epochs : {} \".format(cols, nb_epoch))\n",
    "\n",
    "        #데이터 모델 트레이닝\n",
    "        hist = model_specialist.fit_generator(flipgen.flow(X_train, y_train), \n",
    "                                     #ImageDataGenerator.flow를 통한 학습 데이터의 증가\n",
    "                                     samples_per_epoch=X_train.shape[0],\n",
    "                                     # 완성 된 epoch에 다음 epoch에 대한 단계의 수\n",
    "                                     nb_epoch=nb_epoch, #학습 개수 : 500\n",
    "                                     validation_data=(X_val, y_val), # loss, val_loss의 모델 평가\n",
    "                                     callbacks=[change_lr, early_stop]) # 조기종료\n",
    "\n",
    "        specialists[cols] = model_specialist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_eye_center_x     7039\n",
      "left_eye_center_y     7039\n",
      "right_eye_center_x    7036\n",
      "right_eye_center_y    7036\n",
      "Image                 7049\n",
      "dtype: int64\n",
      "Training model for columns ('left_eye_center_x', 'left_eye_center_y', 'right_eye_center_x', 'right_eye_center_y') for 500 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=(array([[[..., callbacks=[<keras.ca..., steps_per_epoch=175, epochs=500)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "175/175 [==============================] - 287s 2s/step - loss: 0.0060 - val_loss: 0.0051\n",
      "Epoch 2/500\n",
      "175/175 [==============================] - 287s 2s/step - loss: 0.0042 - val_loss: 0.0051\n",
      "Epoch 3/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0043 - val_loss: 0.0051\n",
      "Epoch 4/500\n",
      "175/175 [==============================] - 280s 2s/step - loss: 0.0042 - val_loss: 0.0051\n",
      "Epoch 5/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0042 - val_loss: 0.0051\n",
      "Epoch 6/500\n",
      "175/175 [==============================] - 280s 2s/step - loss: 0.0042 - val_loss: 0.0051\n",
      "Epoch 7/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0041 - val_loss: 0.0051\n",
      "Epoch 8/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0043 - val_loss: 0.0051\n",
      "Epoch 9/500\n",
      "175/175 [==============================] - 77301s 442s/step - loss: 0.0043 - val_loss: 0.0051\n",
      "Epoch 10/500\n",
      "175/175 [==============================] - 286s 2s/step - loss: 0.0042 - val_loss: 0.0051\n",
      "Epoch 11/500\n",
      "175/175 [==============================] - 294s 2s/step - loss: 0.0042 - val_loss: 0.0051\n",
      "Epoch 12/500\n",
      "175/175 [==============================] - 292s 2s/step - loss: 0.0043 - val_loss: 0.0051\n",
      "Epoch 13/500\n",
      "175/175 [==============================] - 296s 2s/step - loss: 0.0042 - val_loss: 0.0051\n",
      "Epoch 14/500\n",
      "175/175 [==============================] - 299s 2s/step - loss: 0.0042 - val_loss: 0.0050\n",
      "Epoch 15/500\n",
      "175/175 [==============================] - 291s 2s/step - loss: 0.0041 - val_loss: 0.0052\n",
      "Epoch 16/500\n",
      "175/175 [==============================] - 291s 2s/step - loss: 0.0041 - val_loss: 0.0051\n",
      "Epoch 17/500\n",
      "175/175 [==============================] - 291s 2s/step - loss: 0.0041 - val_loss: 0.0051\n",
      "Epoch 18/500\n",
      "175/175 [==============================] - 286s 2s/step - loss: 0.0043 - val_loss: 0.0051\n",
      "Epoch 19/500\n",
      "175/175 [==============================] - 287s 2s/step - loss: 0.0042 - val_loss: 0.0051\n",
      "Epoch 20/500\n",
      "175/175 [==============================] - 290s 2s/step - loss: 0.0043 - val_loss: 0.0051\n",
      "Epoch 21/500\n",
      "175/175 [==============================] - 291s 2s/step - loss: 0.0041 - val_loss: 0.0050\n",
      "Epoch 22/500\n",
      "175/175 [==============================] - 287s 2s/step - loss: 0.0043 - val_loss: 0.0050\n",
      "Epoch 23/500\n",
      "175/175 [==============================] - 283s 2s/step - loss: 0.0040 - val_loss: 0.0050\n",
      "Epoch 24/500\n",
      "175/175 [==============================] - 285s 2s/step - loss: 0.0042 - val_loss: 0.0051\n",
      "Epoch 25/500\n",
      "175/175 [==============================] - 283s 2s/step - loss: 0.0041 - val_loss: 0.0051\n",
      "Epoch 26/500\n",
      "175/175 [==============================] - 283s 2s/step - loss: 0.0040 - val_loss: 0.0050\n",
      "Epoch 27/500\n",
      "175/175 [==============================] - 288s 2s/step - loss: 0.0042 - val_loss: 0.0050\n",
      "Epoch 28/500\n",
      "175/175 [==============================] - 288s 2s/step - loss: 0.0040 - val_loss: 0.0049\n",
      "Epoch 29/500\n",
      "175/175 [==============================] - 288s 2s/step - loss: 0.0041 - val_loss: 0.0049\n",
      "Epoch 30/500\n",
      "175/175 [==============================] - 284s 2s/step - loss: 0.0040 - val_loss: 0.0049\n",
      "Epoch 31/500\n",
      "175/175 [==============================] - 285s 2s/step - loss: 0.0040 - val_loss: 0.0049\n",
      "Epoch 32/500\n",
      "175/175 [==============================] - 285s 2s/step - loss: 0.0041 - val_loss: 0.0048\n",
      "Epoch 33/500\n",
      "175/175 [==============================] - 286s 2s/step - loss: 0.0039 - val_loss: 0.0048\n",
      "Epoch 34/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 35/500\n",
      "175/175 [==============================] - 280s 2s/step - loss: 0.0037 - val_loss: 0.0047\n",
      "Epoch 36/500\n",
      "175/175 [==============================] - 280s 2s/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 37/500\n",
      "175/175 [==============================] - 280s 2s/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 38/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 39/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 40/500\n",
      "175/175 [==============================] - 279s 2s/step - loss: 0.0036 - val_loss: 0.0043\n",
      "Epoch 41/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0037 - val_loss: 0.0043\n",
      "Epoch 42/500\n",
      "175/175 [==============================] - 283s 2s/step - loss: 0.0037 - val_loss: 0.0043\n",
      "Epoch 43/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 44/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 45/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0033 - val_loss: 0.0041\n",
      "Epoch 46/500\n",
      "175/175 [==============================] - 284s 2s/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 47/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0030 - val_loss: 0.0041\n",
      "Epoch 48/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 49/500\n",
      "175/175 [==============================] - 288s 2s/step - loss: 0.0033 - val_loss: 0.0041\n",
      "Epoch 50/500\n",
      "175/175 [==============================] - 292s 2s/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 51/500\n",
      "175/175 [==============================] - 289s 2s/step - loss: 0.0034 - val_loss: 0.0041\n",
      "Epoch 52/500\n",
      "175/175 [==============================] - 289s 2s/step - loss: 0.0033 - val_loss: 0.0040\n",
      "Epoch 53/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 54/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0033 - val_loss: 0.0041\n",
      "Epoch 55/500\n",
      "175/175 [==============================] - 283s 2s/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 56/500\n",
      "175/175 [==============================] - 283s 2s/step - loss: 0.0033 - val_loss: 0.0040\n",
      "Epoch 57/500\n",
      "175/175 [==============================] - 280s 2s/step - loss: 0.0032 - val_loss: 0.0041\n",
      "Epoch 58/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0031 - val_loss: 0.0040\n",
      "Epoch 59/500\n",
      "175/175 [==============================] - 283s 2s/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 60/500\n",
      "175/175 [==============================] - 285s 2s/step - loss: 0.0033 - val_loss: 0.0040\n",
      "Epoch 61/500\n",
      "175/175 [==============================] - 283s 2s/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 62/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 63/500\n",
      "175/175 [==============================] - 279s 2s/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 64/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 65/500\n",
      "175/175 [==============================] - 285s 2s/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 66/500\n",
      "175/175 [==============================] - 289s 2s/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 67/500\n",
      "175/175 [==============================] - 290s 2s/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 68/500\n",
      "175/175 [==============================] - 293s 2s/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 69/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 70/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 71/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0030 - val_loss: 0.0038\n",
      "Epoch 72/500\n",
      "175/175 [==============================] - 283s 2s/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 73/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 74/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0030 - val_loss: 0.0038\n",
      "Epoch 75/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 76/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 77/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 78/500\n",
      "175/175 [==============================] - 280s 2s/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 79/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 80/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175/175 [==============================] - 282s 2s/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 81/500\n",
      "175/175 [==============================] - 283s 2s/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 82/500\n",
      "175/175 [==============================] - 284s 2s/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 83/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 84/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 85/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 86/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 87/500\n",
      "175/175 [==============================] - 285s 2s/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 88/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 89/500\n",
      "175/175 [==============================] - 283s 2s/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 90/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 91/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 92/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0030 - val_loss: 0.0035\n",
      "Epoch 93/500\n",
      "175/175 [==============================] - 283s 2s/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 94/500\n",
      "175/175 [==============================] - 280s 2s/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 95/500\n",
      "175/175 [==============================] - 280s 2s/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 96/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 97/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 98/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 99/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 100/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 101/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 102/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 103/500\n",
      "175/175 [==============================] - 283s 2s/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 104/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 105/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 106/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 107/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 108/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 109/500\n",
      "175/175 [==============================] - 283s 2s/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 110/500\n",
      "175/175 [==============================] - 280s 2s/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 111/500\n",
      "175/175 [==============================] - 285s 2s/step - loss: 0.0022 - val_loss: 0.0032\n",
      "Epoch 112/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 113/500\n",
      "175/175 [==============================] - 280s 2s/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 114/500\n",
      "175/175 [==============================] - 285s 2s/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 115/500\n",
      "175/175 [==============================] - 283s 2s/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 116/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 117/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 118/500\n",
      "175/175 [==============================] - 280s 2s/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 119/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 120/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 121/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 122/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0022 - val_loss: 0.0032\n",
      "Epoch 123/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 124/500\n",
      "175/175 [==============================] - 283s 2s/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 125/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 126/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 127/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 128/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 129/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 130/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 131/500\n",
      "175/175 [==============================] - 280s 2s/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 132/500\n",
      "175/175 [==============================] - 280s 2s/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 133/500\n",
      "175/175 [==============================] - 283s 2s/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 134/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 135/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 136/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 137/500\n",
      "175/175 [==============================] - 283s 2s/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 138/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 139/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 140/500\n",
      "175/175 [==============================] - 283s 2s/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 141/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 142/500\n",
      "175/175 [==============================] - 284s 2s/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 143/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 144/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 145/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 146/500\n",
      "175/175 [==============================] - 283s 2s/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 147/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 148/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 149/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 150/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 151/500\n",
      "175/175 [==============================] - 280s 2s/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 152/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 153/500\n",
      "175/175 [==============================] - 283s 2s/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 154/500\n",
      "175/175 [==============================] - 283s 2s/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 155/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 156/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 157/500\n",
      "175/175 [==============================] - 283s 2s/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 158/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 159/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175/175 [==============================] - 282s 2s/step - loss: 0.0020 - val_loss: 0.0030\n",
      "Epoch 160/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 161/500\n",
      "175/175 [==============================] - 280s 2s/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 162/500\n",
      "175/175 [==============================] - 285s 2s/step - loss: 0.0020 - val_loss: 0.0030\n",
      "Epoch 163/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 164/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 165/500\n",
      "175/175 [==============================] - 287s 2s/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 166/500\n",
      "175/175 [==============================] - 290s 2s/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 167/500\n",
      "175/175 [==============================] - 289s 2s/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 168/500\n",
      "175/175 [==============================] - 292s 2s/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 169/500\n",
      "175/175 [==============================] - 280s 2s/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 170/500\n",
      "175/175 [==============================] - 283s 2s/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 171/500\n",
      "175/175 [==============================] - 283s 2s/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 172/500\n",
      "175/175 [==============================] - 283s 2s/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 173/500\n",
      "175/175 [==============================] - 283s 2s/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 174/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 175/500\n",
      "175/175 [==============================] - 279s 2s/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 176/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 177/500\n",
      "175/175 [==============================] - 283s 2s/step - loss: 0.0020 - val_loss: 0.0030\n",
      "Epoch 178/500\n",
      "175/175 [==============================] - 280s 2s/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 179/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 180/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 181/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 182/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 183/500\n",
      "175/175 [==============================] - 279s 2s/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 184/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 185/500\n",
      "175/175 [==============================] - 279s 2s/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 186/500\n",
      "175/175 [==============================] - 280s 2s/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 187/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 188/500\n",
      "175/175 [==============================] - 284s 2s/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 189/500\n",
      "175/175 [==============================] - 283s 2s/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 190/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 191/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 192/500\n",
      "175/175 [==============================] - 280s 2s/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 193/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 194/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 195/500\n",
      "175/175 [==============================] - 280s 2s/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 196/500\n",
      "175/175 [==============================] - 283s 2s/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 197/500\n",
      "175/175 [==============================] - 283s 2s/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 198/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 199/500\n",
      "175/175 [==============================] - 283s 2s/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 200/500\n",
      "175/175 [==============================] - 283s 2s/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 201/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 202/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 203/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 204/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 205/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 206/500\n",
      "175/175 [==============================] - 280s 2s/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 207/500\n",
      "175/175 [==============================] - 283s 2s/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 208/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 209/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 210/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 211/500\n",
      "175/175 [==============================] - 283s 2s/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 212/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 213/500\n",
      "175/175 [==============================] - 280s 2s/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 214/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 215/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 216/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 217/500\n",
      "175/175 [==============================] - 280s 2s/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 218/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 219/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 220/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 221/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 222/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 223/500\n",
      "175/175 [==============================] - 284s 2s/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 224/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 225/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 226/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 227/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 228/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 229/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 230/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 231/500\n",
      "175/175 [==============================] - 283s 2s/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 232/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 233/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 234/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 235/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 236/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 237/500\n",
      "175/175 [==============================] - 283s 2s/step - loss: 0.0019 - val_loss: 0.0028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 238/500\n",
      "175/175 [==============================] - 283s 2s/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 239/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 240/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 241/500\n",
      "175/175 [==============================] - 280s 2s/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 242/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 243/500\n",
      "175/175 [==============================] - 279s 2s/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 244/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 245/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 246/500\n",
      "175/175 [==============================] - 283s 2s/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 247/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 248/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 249/500\n",
      "175/175 [==============================] - 280s 2s/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 250/500\n",
      "175/175 [==============================] - 279s 2s/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 251/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 252/500\n",
      "175/175 [==============================] - 279s 2s/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 253/500\n",
      "175/175 [==============================] - 283s 2s/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 254/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 255/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 256/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 257/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 258/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 259/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 260/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 261/500\n",
      "175/175 [==============================] - 280s 2s/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 262/500\n",
      "175/175 [==============================] - 280s 2s/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 263/500\n",
      "175/175 [==============================] - 283s 2s/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 264/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 265/500\n",
      "175/175 [==============================] - 284s 2s/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 266/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 267/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 268/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 269/500\n",
      "175/175 [==============================] - 283s 2s/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 270/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 271/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 272/500\n",
      "175/175 [==============================] - 283s 2s/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 273/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 274/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 275/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 276/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 277/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 278/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0014 - val_loss: 0.0028\n",
      "Epoch 279/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 280/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 281/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 282/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 283/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 284/500\n",
      "175/175 [==============================] - 280s 2s/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 285/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 286/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 287/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 288/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 289/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 290/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 291/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 292/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 293/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 294/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 295/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 296/500\n",
      "175/175 [==============================] - 280s 2s/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 297/500\n",
      "175/175 [==============================] - 280s 2s/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 298/500\n",
      "175/175 [==============================] - 283s 2s/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 299/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 300/500\n",
      "175/175 [==============================] - 283s 2s/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 301/500\n",
      "175/175 [==============================] - 280s 2s/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 302/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 303/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 304/500\n",
      "175/175 [==============================] - 280s 2s/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 305/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 306/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 307/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 308/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 309/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 310/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 311/500\n",
      "175/175 [==============================] - 280s 2s/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 312/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 313/500\n",
      "175/175 [==============================] - 283s 2s/step - loss: 0.0015 - val_loss: 0.0029\n",
      "Epoch 314/500\n",
      "175/175 [==============================] - 285s 2s/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 315/500\n",
      "175/175 [==============================] - 292s 2s/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 316/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175/175 [==============================] - 288s 2s/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 317/500\n",
      "175/175 [==============================] - 288s 2s/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 318/500\n",
      "175/175 [==============================] - 283s 2s/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 319/500\n",
      "175/175 [==============================] - 284s 2s/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 320/500\n",
      "175/175 [==============================] - 285s 2s/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 321/500\n",
      "175/175 [==============================] - 281s 2s/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 322/500\n",
      "175/175 [==============================] - 285s 2s/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 323/500\n",
      "175/175 [==============================] - 285s 2s/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 324/500\n",
      "175/175 [==============================] - 285s 2s/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 325/500\n",
      "175/175 [==============================] - 283s 2s/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 326/500\n",
      "175/175 [==============================] - 285s 2s/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 327/500\n",
      "175/175 [==============================] - 285s 2s/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 328/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 329/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 330/500\n",
      "175/175 [==============================] - 282s 2s/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 331/500\n",
      "175/175 [==============================] - 283s 2s/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 332/500\n",
      "175/175 [==============================] - 283s 2s/step - loss: 0.0015 - val_loss: 0.0029\n",
      "Epoch 333/500\n",
      "175/175 [==============================] - 284s 2s/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 334/500\n",
      "175/175 [==============================] - 283s 2s/step - loss: 0.0015 - val_loss: 0.0029\n",
      "Epoch 335/500\n",
      "175/175 [==============================] - 285s 2s/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 336/500\n",
      "175/175 [==============================] - 283s 2s/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 337/500\n",
      "175/175 [==============================] - 284s 2s/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 338/500\n",
      " 23/175 [==>...........................] - ETA: 4:06 - loss: 0.0016"
     ]
    }
   ],
   "source": [
    "fit_specialists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
